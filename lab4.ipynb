{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4 - Pytorch and Convolutional Deep Networks\n",
    "\n",
    "Objectives:\n",
    "1. *Write a convolutional neural network for the MNIST database*\n",
    "\n",
    "In this lab, we will use Pytorch to write Convolutional Neural Networks. We are still going to use the MNIST database and the code to load it, as in the previous lab.\n",
    "\n",
    "<center><img src=\"https://upload.wikimedia.org/wikipedia/commons/2/27/MnistExamples.png\" height=\"250px\"></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = datasets.MNIST(\"\", train=True, download=True, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "test = datasets.MNIST(\"\", train=False, download=True, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "# Get data and store in variables \"trainset\" and \"testset\"\n",
    "trainset = torch.utils.data.DataLoader(train, batch_size=10, shuffle=True)\n",
    "testset = torch.utils.data.DataLoader(test, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike the previous lab though, we are going to make use of convolutional layers, instead of linear ones to classify the inputs.\n",
    "\n",
    "The network will look like this:\n",
    "\n",
    "<center><img src=\"https://i.imgur.com/ubyPlIg.png\" height=\"275px\"></center>\n",
    "\n",
    "where the the activation function for each layer is the rectified linear function (ReLu) $r(\\cdot)$, the pooling layer $M_p$ takes the maximum value of a patch of the image and the output layer is made of softmax functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a class from nn.Module. This PyTorch module\n",
    "# contains the building blocks to create neural networks.\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"Defines the neural network architecure.\"\"\"\n",
    "        \n",
    "        super().__init__() # calls __init() of nn.Module superclass\n",
    "\n",
    "        # nn.Conv2d is the convolutional layer we're interested in\n",
    "        #\n",
    "        # First two inputs are layer dimenensions\n",
    "        # Third input represents convolution kernel dimension (5x5 kernel here)\n",
    "        # Last parameter sets the padding for the image\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 32, 5, padding=2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 5, padding=2)\n",
    "\n",
    "        self.fc1 = nn.Linear(64*7*7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def convs(self, x):\n",
    "        \"\"\"Applies the max function over a patch of the image (2x2 patch, in this case).\"\"\"\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2,2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), (2,2))\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"Computes the output of the network for an input x.\"\"\"\n",
    "        x = self.convs(x)\n",
    "        x = x.view(-1, 64*7*7)\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return F.softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Why is the padding set to 2?*\n",
    "\n",
    "\n",
    "*As you can see, the linear layers are set up in such a way to take the “flattened” output of our convolutional layer, as their input is a vector. Can you explain why the input is set to 64\\*7\\*7?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to finish this network we still need to set up the optimiser and error function, and compute the gradient with respect to the loss, then train for a number of iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net() # create instance of neural network\n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001)\n",
    "# Using Adam, as this is the standard for neural networks at the moment\n",
    "\n",
    "epochs = 3\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for data in trainset:\n",
    "        X, y = data\n",
    "        net.zero_grad()  # sets up gradient stored in each variable of the network to zero\n",
    "        output = net.forward(X)\n",
    "        loss = F.nll_loss(output,y) # working with classifier, so using cross-entropy for loss func\n",
    "        loss.backward()  # computes gradient wrt loss function over each network param\n",
    "        optimizer.step() # updates network paramaters (according to optimisation algo) and grad stored in each variable\n",
    "\n",
    "    print('Loss: ', loss)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    # no_grad means network won't update gradient stored in each\n",
    "    # variable during test session as there is no loss to be minimised\n",
    "    \n",
    "    for data in testset:\n",
    "        X, y = data\n",
    "        output = net.forward(X)\n",
    "        for idx, i in enumerate(output):\n",
    "            if torch.argmax(i) == y[idx]:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "\n",
    "print('Accuracy: ', round(correct/total, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*You’ll notice that this code takes significantly more time to run than the previous one. Do you know why that’s the case?*"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ff39433d367775670857b5a26fe0f62904f7bab0aa1764437f86463c08ac313f"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
