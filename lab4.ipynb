{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4 - Pytorch and Convolutional Deep Networks\n",
    "\n",
    "Objectives:\n",
    "1. *Write a convolutional neural network for the MNIST database*\n",
    "\n",
    "In this lab, we will use Pytorch to write Convolutional Neural Networks. We are still going to use the MNIST database and the code to load it, as in the previous lab.\n",
    "\n",
    "<center><img src=\"https://upload.wikimedia.org/wikipedia/commons/2/27/MnistExamples.png\" height=\"250px\"></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = datasets.MNIST(\n",
    "    \"\", train=True, download=True, transform=transforms.Compose([transforms.ToTensor()])\n",
    ")\n",
    "test = datasets.MNIST(\n",
    "    \"\", train=False, download=True, transform=transforms.Compose([transforms.ToTensor()])\n",
    ")\n",
    "\n",
    "# Get data and store in variables \"trainset\" and \"testset\"\n",
    "trainset = torch.utils.data.DataLoader(train, batch_size=10, shuffle=True)\n",
    "testset = torch.utils.data.DataLoader(test, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike the previous lab though, we are going to make use of convolutional layers, instead of linear ones to classify the inputs.\n",
    "\n",
    "The network will look like this:\n",
    "\n",
    "<center><img src=\"https://i.imgur.com/ubyPlIg.png\" height=\"275px\"></center>\n",
    "\n",
    "where the the activation function for each layer is the rectified linear function (ReLu) $r(\\cdot)$, the pooling layer $M_p$ takes the maximum value of a patch of the image and the output layer is made of softmax functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a class from nn.Module. This PyTorch module\n",
    "# contains the building blocks to create neural networks.\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"Defines the neural network architecure.\"\"\"\n",
    "\n",
    "        super().__init__()  # calls __init()__ of nn.Module superclass\n",
    "\n",
    "        # nn.Conv2d is the convolutional layer we're interested in\n",
    "        #\n",
    "        # First two inputs are layer dimenensions (input image & convolution output)\n",
    "        # Third input represents convolution kernel dimension (5x5 kernel here)\n",
    "        # Last parameter sets the padding for the image\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 32, 5, padding=2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 5, padding=2)\n",
    "\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def convs(self, x):\n",
    "        \"\"\"Applies the max function over a patch of the image (2x2 patch, in this case).\"\"\"\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), (2, 2))\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Computes the output of the network for an input x.\"\"\"\n",
    "        x = self.convs(x)\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return F.softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Why is the padding set to 2?*\n",
    "\n",
    "Padding, the act of filling the image with a series of 0 on the edges, is done in order to avoid cropping effects due to kernels. It is set to as a large a value it can be without exceeding half the kernel size (which is 5x5), i.e. 2.\n",
    "\n",
    "\n",
    "*As you can see, the linear layers are set up in such a way to take the “flattened” output of our convolutional layer, as their input is a vector. Can you explain why the input is set to 64\\*7\\*7?*\n",
    "\n",
    "Firstly, the output of the last non-linear layer is a series of 64 matrices. Then, we must recall that each image/input is a 28\\*28 matrix. Each of these matrices goes through two pooling layers that have `kernel_size` and `stride` of 2, meaning the height and width will be halved twice, meaning that each matrix is now 7\\*7. Therefore the input to the linear layers is 64\\*7\\*7. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to finish this network we still need to set up the optimiser and error function, and compute the gradient with respect to the loss, then train for a number of iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: -0.997342586517334\n",
      "Epoch 1: -1.0\n",
      "Epoch 2: -1.0\n",
      "Accuracy:  0.875\n"
     ]
    }
   ],
   "source": [
    "net = Net()  # create instance of neural network\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "# Using Adam, as this is the standard for neural networks at the moment\n",
    "\n",
    "epochs = 3\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for data in trainset:\n",
    "        X, y = data\n",
    "        net.zero_grad()  # sets up gradient stored in each variable of the network to zero\n",
    "        output = net.forward(X)\n",
    "        loss = F.nll_loss(\n",
    "            output, y\n",
    "        )  # working with classifier, so using cross-entropy for loss func\n",
    "        loss.backward()  # computes gradient wrt loss function over each network param\n",
    "        optimizer.step()  # updates network paramaters (according to optimisation algo) and grad stored in each variable\n",
    "\n",
    "    print(f\"Epoch {epoch}: {loss}\")\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    # no_grad means network won't update gradient stored in each\n",
    "    # variable during test session as there is no loss to be minimised\n",
    "\n",
    "    for data in testset:\n",
    "        X, y = data\n",
    "        output = net.forward(X)\n",
    "        for idx, i in enumerate(output):\n",
    "            if torch.argmax(i) == y[idx]:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "\n",
    "print(\"Accuracy: \", round(correct / total, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*You’ll notice that this code takes significantly more time to run than the previous one. Do you know why that’s the case?*\n",
    "\n",
    "Convolution steps require many more primitive operations than those for linear layers, e.g. multiplication, summation, copy/access. In a linear layer, weights and inputs are merely multiplied together, whereas with convolution, kernels are multiplied as many times as there are outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: -0.9991691708564758\n",
      "Epoch 1: -0.800000011920929\n",
      "Epoch 2: -0.9100052118301392\n",
      "accuracy:  0.894\n"
     ]
    }
   ],
   "source": [
    "# Using the average function instead of the max function in the pooling layer\n",
    "\n",
    "# Create a class from nn.Module. This PyTorch module\n",
    "# contains the building blocks to create neural networks.\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"Defines the neural network architecure.\"\"\"\n",
    "\n",
    "        super().__init__()  # calls __init()__ of nn.Module superclass\n",
    "\n",
    "        # nn.Conv2d is the convolutional layer we're interested in\n",
    "        #\n",
    "        # First two inputs are layer dimenensions (input image & convolution output)\n",
    "        # Third input represents convolution kernel dimension (5x5 kernel here)\n",
    "        # Last parameter sets the padding for the image\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 32, 5, padding=2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 5, padding=2)\n",
    "\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def convs(self, x):\n",
    "        \"\"\"Applies the average function over a patch of the image (2x2 patch, in this case).\"\"\"\n",
    "        x = F.avg_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.avg_pool2d(F.relu(self.conv2(x)), (2, 2))\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Computes the output of the network for an input x.\"\"\"\n",
    "        x = self.convs(x)\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return F.softmax(x, dim=1)\n",
    "\n",
    "\n",
    "net = Net()  # create instance of neural network\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "# Using Adam, as this is the standard for neural networks at the moment\n",
    "\n",
    "epochs = 3\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for data in trainset:\n",
    "        X, y = data\n",
    "        net.zero_grad()  # sets up gradient stored in each variable of the network to zero\n",
    "        output = net.forward(X)\n",
    "        loss = F.nll_loss(\n",
    "            output, y\n",
    "        )  # working with classifier, so using cross-entropy for loss func\n",
    "        loss.backward()  # computes gradient wrt loss function over each network param\n",
    "        optimizer.step()  # updates network paramaters (according to optimisation algo) and grad stored in each variable\n",
    "\n",
    "    print(f\"Epoch {epoch}: {loss}\")\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    # no_grad means network won't update gradient stored in each\n",
    "    # variable during test session as there is no loss to be minimised\n",
    "\n",
    "    for data in testset:\n",
    "        X, y = data\n",
    "        output = net.forward(X)\n",
    "        for idx, i in enumerate(output):\n",
    "            if torch.argmax(i) == y[idx]:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "\n",
    "print(\"accuracy: \", round(correct / total, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Does the performance of the network improve?*\n",
    "\n",
    "The network performance is improved slightly, with accuracy increasing from 0.875 to 0.894. This could be due to max pooling selecting brighter pixels from the image, which may not be as useful when the background is light and areas of interest dark, as our the digits analysed here.\n",
    "\n",
    "*Is it reasonable to expect to reach a 100% classification accuracy?*\n",
    "\n",
    "Probably not, as at this point the model would likely be overfit, where it is evaluating on the noise rather than the actual useful information. This would also require a loss of 0."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ff39433d367775670857b5a26fe0f62904f7bab0aa1764437f86463c08ac313f"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
